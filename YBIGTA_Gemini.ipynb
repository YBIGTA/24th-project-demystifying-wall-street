{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oK-qH_41bGwG"
   },
   "source": [
    "참고한 블로그:\n",
    "https://yunwoong.tistory.com/297"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw-HHa4DaruN"
   },
   "source": [
    "TextGenerativeModel document: https://cloud.google.com/vertex-ai/docs/generative-ai/sdk-for-llm/sdk-use-text-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHrAmi4W12lB"
   },
   "source": [
    "https://console.cloud.google.com/welcome/new?project=ybigta-414314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QC6Vlhgu2HZ3",
    "outputId": "249bb3f7-fc52-4613-d9c4-de8a1b4597e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform>=1.38 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (1.41.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (4.25.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (1.23.0)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (21.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (3.17.2)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (2.0.2)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (2.17.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (1.12.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform>=1.38) (2.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (1.62.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (2.27.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (2.27.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (1.60.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (1.60.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (4.7.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.38) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.38) (2.8.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.38) (2.4.1)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform>=1.38) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from packaging>=14.3->google-cloud-aiplatform>=1.38) (3.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.38) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform>=1.38) (2021.10.8)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\shgla\\anaconda3\\lib\\site-packages (from shapely<3.0.0dev->google-cloud-aiplatform>=1.38) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"google-cloud-aiplatform>=1.38\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YsEw1wID21o_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Image\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Qyt2mdWUGqQF"
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/ybigta-414314-448985d72b01.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f__ypXL121kp"
   },
   "outputs": [],
   "source": [
    "project_id = \"ybigta-414314\"\n",
    "location = \"asia-northeast3\" #한국 서울"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "58tSQVfb21i1"
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "DTfv0oh821eZ",
    "outputId": "99b20441-dd10-4071-9696-a9cf68db6fbb"
   },
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "\n",
    "\n",
    "#test\n",
    "print(model.predict(\n",
    "    \"What is the best recipe for banana bread? Recipe:\",\n",
    "    # The following are optional parameters:\n",
    "    #max_output_tokens=128,\n",
    "    #temperature=0,\n",
    "    #top_p=1,\n",
    "    #top_k=5,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "# !gcloud config set project ybigta-414314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "model = GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6x7guzUD1x3e"
   },
   "outputs": [],
   "source": [
    "def summarize(news_article: str) -> str:\n",
    "\n",
    "  #Generate a summarization of the given news.\n",
    "  model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "  prompt = f\"Summarize the following financial news article:\\n\\n{news_article}\"\n",
    "\n",
    "  summary = model.predict(\n",
    "      prompt,\n",
    "      max_output_tokens=150,\n",
    "      temperature=0.7,\n",
    "      top_p=0.9,\n",
    "      top_k=10)\n",
    "\n",
    "  return summary.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "yrkX8H3L21NK",
    "outputId": "cb51f6d8-4f2f-47b9-d2f2-33bbe706d354"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (<ipython-input-10-07163a8828ef>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-07163a8828ef>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    prompt = f\"\"\"Identify economic terms in the following financial news article. :\\n\\n{news_article}\" #prompt engineering 필요\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def detect_economic_terms(news_article: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Tries to detect economic terms in a financial news article using the TextGenerationModel.\n",
    "\n",
    "    Parameters:\n",
    "    - news_article (str): The financial news article to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: List of detected economic terms.\n",
    "    \"\"\"\n",
    "    # Build a prompt for economic term detection\n",
    "    prompt = f\"\"\"Identify economic terms in the following financial news article.\n",
    "                  Example 1\n",
    "                  Input:\n",
    "                  Emerging markets soared more than 33 percent in 2017, and Todd Gordon of TradingAnalysis.com says the rally won't stop. A big part of the rally in emerging markets, tracked by the emerging market ETF EEM , was a weak dollar. And given that Gordon still sees the inverse relationship between EEM and the dollar, measured in his charts by the dollar-tracking ETF UUP , he believes the U.S. currency will continue to help the group. \"We have a falling U.S. dollar, which will support international and emerging market currencies and will give those EEM stocks a boost,\" Gordon said Tuesday on CNBC's \"Trading Nation.\" The U.S. dollar in 2017 posted its worst annual performance in 14 years, while EEM saw its best performance since 2013. As for how high the latter could go, Gordon says EEM has broken \"resistance\" at around $45, which was the ETF's 2014 highs. That $45 region is now what he calls \"support,\" and he sees it rallying to $50, which the ETF hasn't hit since mid-2011. To play for a move higher, Gordon suggested buying the February 48/50 call spread for 72 cents, or $72 per options contract. This means that if EEM closes above $50 on Feb. 16, then Gordon could make a maximum reward of $128 on the trade. But if EEM were to close below $48, then Gordon would lose the $72 he paid for the trade. As a result, Gordon wants to establish a point at which to get out. \"If the 72 cent premium we just laid out gets cut in half to about 36 cents, let's cut the trade and move on,\" he said. EEM started the year off strong, rallying more than 1 percent on Tuesday.\n",
    "                  Output:\n",
    "\n",
    "                  :\\n\\n{news_article}\"\"\" #prompt engineering 필요\n",
    "\n",
    "    # Instantiate the TextGenerationModel\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@002\") #NER 고려 필요\n",
    "\n",
    "    # Generate content\n",
    "    generated_content = model.predict(\n",
    "        prompt,\n",
    "        max_output_tokens=200,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=10\n",
    "    )\n",
    "\n",
    "    # Extract economic terms (simple example, may not be accurate)\n",
    "    economic_terms = [term.strip() for term in generated_content.split()] #이 splitting이 가능하도록 prompt engineering 필요\n",
    "\n",
    "    return economic_terms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4llYY40521LG"
   },
   "outputs": [],
   "source": [
    "\"def get_economic_term_definitions(economic_terms: List[str]) -> List[str]:\n",
    "\n",
    "  # input에 원문, 요약본, term list가 한번에 들어가야 context가 반영될듯\n",
    "    \"\"\"\n",
    "    Gets definitions for given economic terms using a TextGenerationModel.\n",
    "\n",
    "    Parameters:\n",
    "    - economic_terms (List[str]): List of economic terms.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: List of definitions for each economic term.\n",
    "    \"\"\"\n",
    "    # Instantiate the TextGenerationModel\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "\n",
    "    # Build a prompt for definitions of multiple economic terms\n",
    "    prompt = f\"Define the following economic terms: {', '.join(economic_terms)}\"\n",
    "\n",
    "    # Generate content using the prompt\n",
    "    generated_content = model.predict(\n",
    "        prompt,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=10\n",
    "    )\n",
    "\n",
    "    # Split the generated content into definitions for each term\n",
    "    definitions = [definition.strip() for definition in generated_content.split('\\n')]\n",
    "\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPQRdbvagIiZ"
   },
   "outputs": [],
   "source": [
    "def start(news_article: str) -> None:\n",
    "  summary = summarize(news_article)\n",
    "  terms = detect_economic_terms(news_article)\n",
    "  definitions = get_economic_term_definitions(terms)\n",
    "\n",
    "  return summary, terms, definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0isq7ttif61S"
   },
   "outputs": [],
   "source": [
    "news = input(\"news article: \")\n",
    "summary, terms, definitions = start(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpnBeveDd4Yd"
   },
   "source": [
    "##TODO\n",
    "1. zero-shot, one-shot, few-shot 시도\n",
    "2. `detect_economic_terms()`과 `get_economic_term_definitions()`에서 splitting이 가능하도록 output이 나오게 하기\n",
    "3.  `detect_economic_terms()`에서 NER 고려해보기.\n",
    "4. `get_economic_term_definitions()`을 TextGenerativeModel에게 시키는 것이 맞을까?\n",
    "5. User의 input과 내 코드가 어떻게 연결되는지 물어보기\n",
    "6. 그걸 알아낸 다음 User가 input 했을 때 모든 function이 작동하도록 연결시키기 (완)\n",
    "7. `get_economic_term_definitions()`에 TextGenerativeModel을 여전히 사용할 거면, input으로 기사 원문, 요약본도 같이 넘겨주기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1iq8qAveX4f"
   },
   "source": [
    "Crawling에서 궁금한 점:\n",
    "- subscribe를 해야 볼 수 있는 기사를 크롤링으로 보는 건 불법 아닌가요?\n",
    "- 불가능하다면 유저가 직접 복붙하는 방법은 어떤가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQpdUI1wdUkV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9J2MMYic65G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Wl7JV-Wc6x2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiO3JUAt21I7"
   },
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPwxNJ6x21GG"
   },
   "outputs": [],
   "source": [
    "#NER 사용\n",
    "\n",
    "import spacy\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "def detect_economic_terms(news_article: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Detects economic terms in a financial news article.\n",
    "\n",
    "    Parameters:\n",
    "    - news_article (str): The financial news article.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of detected economic terms.\n",
    "    \"\"\"\n",
    "    # Simple example: Use spaCy for named entity recognition\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(news_article)\n",
    "\n",
    "    # Extract economic terms (e.g., organizations or monetary values)\n",
    "    economic_terms = [entity.text for entity in doc.ents if entity.label_ in [\"ORG\", \"MONEY\"]]\n",
    "\n",
    "    return economic_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PIisZr720yq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceOJMlnebrZ_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMC76CvybrXa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6U4799LbrSz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Smb52SSCbrQK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbbPC8H-brNQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
